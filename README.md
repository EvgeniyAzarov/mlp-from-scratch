# MLP from scratch
Pure numpy implementation of multi-layer perceptron with ReLU activations and softmax loss

![loss](imgs/loss.png)
![classification](imgs/classification.png)
